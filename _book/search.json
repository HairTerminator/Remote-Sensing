[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary",
    "section": "",
    "text": "This is the learning diary for remote sensing module. Written in Markdown and editable codes."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Hello! My name is Yinhao Ren and I am a USS student in CASA. Even though I am familiar with remote sensing somewhat, I haven’t done something really fascinating and attractive about this topic. So here I am, looking forword to learn something fun and hope I can pass this module!"
  },
  {
    "objectID": "wk1.html",
    "href": "wk1.html",
    "title": "1  An Introduction to Remote Sensing",
    "section": "",
    "text": "This week the introductory knowledge of remote sensing is mainly introduced in four main aspects. First, the source and application of remote sensing, processing and analyzing data received from satellites, drones, mobile phones, etc., can be applied to decision-making analysis in cities, forests, oceans, etc.; second, the type of sensor, There are two types of sensors, active and passive. The important difference between these two is whether they can send energy independently and get feedback; third, the energy interaction on the earth’s surface, such as atmospheric scattering, the existence of electromagnetic waves, etc.; fourth, introduceing four important resolutions, spatial resolution, spectral resolution, time resolution and radiation resolution. For the experimental part of this week, the course learned how to download the Sentinel-2 satellite image and perform basic processing and display functions. After downloading the target satellite image from the open website, we can first open the true color image (RGB three-band) in QGIS. For Sentinel-2 satellite image band description is as followsWhen we use the Snap software to open an image, we first perform a resampling operation, and then we can use the 432 three bands to perform band fusion to obtain a true color image. A case of a true color image is as followsWe can also use Snap to perform image subsetting, scatter plotting comparison and other activities."
  },
  {
    "objectID": "wk1.html#applications",
    "href": "wk1.html#applications",
    "title": "1  An Introduction to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nThere are many applications of remote sensing, which are involved in different fields. Peng Chen (2023) used multi-source remote sensing data to effectively detect river water quality, with an accuracy of nearly 90%; Wujian Ye (2022) used remote sensing data combined with deep learning methods to classify and identify pests and diseases in forests, and the recall rate up to 50%. To put it simply, its research is to replace the hysteresis and low resolution of satellite remote sensing with the effectiveness and high resolution of drone remote sensing, it performed data enhancement, labeling, etc. on the images of drones, and finally put them into neural networks abd trained in the network model. Ultimately, they got the corresponding results; Zhou Weimo(2022) used the satellite remote sensing data to predict the yield of wheat at the county level in China with the best R square of 0.79. Most of the methods in these articles are based on satellite or drone remote sensing data as the data source, combined with some typical machine learning algorithms such as random forest, support vector machine, etc. to formulate a model, and finally get the corresponding precision results. I think these methods can effectively overcome difficulties, such as field research, funding, coverage area, etc., and remote sensing images can be used as the basic data source when dealing with large-scale single-type targets."
  },
  {
    "objectID": "wk1.html#reflection",
    "href": "wk1.html#reflection",
    "title": "1  An Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nAfter reading some relevant literature and understanding research cases, I think that the application of remote sensing in today’s society must be deeply integrated with forecasting models to a large extent. An obvious feature of the application of remote sensing is statistical expression based on spatial information, which means models are inseparable. Prediction is an unavoidable topic in industrial applications. Therefore, it is necessary to mine remote sensing prediction models and express the spatiotemporal characteristics of the model through spatial data visualization. In the case studies metioned above, the thematic maps and related reports are the most direct products of remote sensing. However, I think the results can be digitized and informatized, like the results can be made into web pages and apps and processed through some shortcuts, such as QR code or link."
  },
  {
    "objectID": "wk2.html",
    "href": "wk2.html",
    "title": "2  Portfolio tools: Xaringan and Quarto",
    "section": "",
    "text": "https://hairterminator.github.io/"
  },
  {
    "objectID": "wk3.html",
    "href": "wk3.html",
    "title": "3  Remote sensing data",
    "section": "",
    "text": "This week’s course mainly involves an introduction to remote sensing data and basic processing operations. At present, there are two main types of satellite sensors: whisk broom and push broom. In order to better understand and use satellite image data, the working principles of these two sensors need to be noted:\n\n\nWhisk broom is sometimes called Spotlight or Across Track Scanners. It uses a “mirror” to reflect light to a detector and uses a “mirror” to move back and forth to collect the value measured from a pixel. Such moving parts are expensive and prone to damage.\n\n\n\nFigure 1, The direction of the whisk broom is perpendicular to the flight path, collecting one pixel at a time, and the image comes fromFlorianhillen\n\n\nAll Landsat sensors prior to Landsat 8 were of the whisk-broom type, and the Landsat 8 OLI devices were of the push-broom type.\n\n\n\nPush-brooms, sometimes called along track scanners, use detectors placed perpendicular to the direction of flight of the spacecraft, which collect images one line at a time as the vehicle flies forward (as shown in the figure below) . The signal received by push-broom is stronger than that of whisk-broom, because the time of whisk-broom in one pixel is very long. A certainty with pushbroom is that the detectors may have different sensitivities, which can lead to image streak noise if not calibrated properly.\n\n\n\nFigure 2, the linear array detector moves with the spacecraft to generate continuous image data, similar to pushing a broom forward, the image comes fromFlorianhillen\n\n\nThe current SPOT, IRS, QuickBird, OrbView, IKONOS, Worldview, GeoEYE, and other sensors are all push-broom.\n\n\n\nRemote sensing image correction is divided into geometric correction and radiometric correction. Geometric correction is subdivided into coarse correction, fine correction, hybrid correction, orthorectification, etc. Radiometric correction is divided into radiometric calibration, radiometric correction, atmospheric correction, etc. These concepts are easy to confuse, so we need to understand the purpose and process of each correction. After going through relevant information, I think I can now clearly present each step.\n\n\nIt refers to using a series of mathematical models to correct and eliminate the deformation caused when the geometric position, shape, size, orientation and other characteristics of the objects on the original image are inconsistent with the expression requirements in the reference system. These deformations are often caused by factors such as the deformation of photographic materials, the distortion of the objective lens, atmospheric refraction, the curvature of the earth, the rotation of the earth, and terrain fluctuations.\nGeometric correction is the process of eliminating or correcting geometric errors of remote sensing images. The deformation errors of remote sensing images can be roughly divided into two categories: static errors and dynamic errors. Referring to the two error categories, geometric correction is divided into several types: geometric coarse correction, geometric fine correction, hybrid correction and orthorectification. The correction we often refer to is fine correction.\nGeometric Coarse Correction: Correction for the cause of distortion. (Distortion causes: distortion of photographic material, distortion of objective lens, curvature of the earth, rotation of the earth)\nGeometric fine correction: geometric correction using control points, which uses a mathematical model to approximately describe the geometric distortion process of remote sensing images, and uses some corresponding points between the distorted remote sensing images and the standard map (that is, the control point data pairs ) to obtain the geometric distortion model, and then use this model to correct the geometric distortion, which does not consider the cause of the straight distortion.\nHybrid correction: The geometric rough correction and the geometric fine correction are done together, and it often includes the precise ephemeris into the correction model.\nOrthorectification generally selects some ground control points on the photo, and uses the digital elevation model (DEM) data within the range of the photo that has been acquired to simultaneously perform tilt correction and projection difference correction on the image, and resample the image into an orthographic image. After mosaicing multiple orthophotos together and performing color balance processing, the images cut out within a certain range are orthophotos.\n\n\n\n\nConcept\n\nThe intensity of radiation entering the sensor is reflected on the image as a brightness value (or gray value). The greater the radiation intensity, the greater the brightness value. This value is mainly affected by two physical quantities: one is the radiation intensity of solar radiation hitting the ground, and the other is the spectral reflectance of ground objects. When the solar radiation is the same, the difference in brightness on the image directly reflects the difference in the reflectivity of the ground. But, in the actual measurement, it is found that the radiation intensity value is also affected by other factors, and this changed part is the part that needs to be corrected, so it is called radiometric distortion.\nThe causes of radiation distortion are: (1) the error of the sensor itself (2) the influence of the atmosphere on radiation (3) the influence of terrain on radiation (terrain correction)\n\nRadiometric correction method\n\n\nHistogram minimum value removal method\nRegression analysis method\n\n\nFor the cause of radiometric distortion, complete radiation correction includes: radiometric correction, sensor correction, atmospheric correction, terrain correction and sun altitude correction.\n\nDN value (Digital Number): the brightness value of a remote sensing image pixel, and it records the gray value of ground features. Unitless, it is an integer value, and the value is related to the radiation resolution of the sensor, the emissivity of ground objects, the transmittance of the atmosphere, and the scattering rate. It reflects the radiation rate radiance of the surface features\nSurface albedo: The ratio of the amount of ground reflected radiation to the amount of incident radiation, which characterizes the ability of the ground to absorb and reflect solar radiation. The greater the reflectivity, the less solar radiation the ground absorbs; the smaller the reflectivity, the more solar radiation the ground absorbs, said: surface albedo\n\n\nRadiation calibration means that when users need to calculate the spectral reflectance or spectral radiance of ground objects, or when they need to compare images acquired by different sensors at different times, they must convert the brightness gray value of the image into absolute radiance. This process is radiometric calibration.\n\n\n\n\nConcept\n\nThe purpose of atmospheric correction is to eliminate the influence of factors such as atmosphere and light on the reflection of ground objects, obtain real physical model parameters such as surface reflectance, radiation, and surface temperature, and use them to eliminate water vapor, oxygen, carbon dioxide, methane, and ozone in the atmosphere. In most cases, atmospheric correction is also the process of inverting the true reflectance of ground objects.\n\nClassification Method\n\n\nAbsolute atmospheric correction methods: MORTRAN model, LOWTRAN model, ACTOR model and 6S model based on radiative transfer\nRelative atmospheric correction methods: Statistical-based invariant target method, histogram matching method."
  },
  {
    "objectID": "wk3.html#application",
    "href": "wk3.html#application",
    "title": "3  Remote sensing data",
    "section": "3.2 Application",
    "text": "3.2 Application\nYuanyuan Pan(2018) aimed at the lack of research on the atmospheric correction of Sentinel-2A satellites, selected three types of ground objects, forests, water bodies, and urban buildings as the research objects, and analyzed the changes in reflectance before and after atmospheric correction of the Sentinel-2A single-band channel; at the same time, Landsat- 8, Gaofen-1 (GF-1) were used as auxiliary data, and the research was carried out from three aspects: the reflectance curve of homogeneous pixel after atmospheric correction of three sensors, and the change of vegetation index before and after atmospheric correction. The results showed that: 1) After atmospheric correction of Sentinel-2A, the reflectance of the visible light channel becomes smaller, and the longer the wavelength is, the less significant the effect of atmospheric correction is; the reflectivity of near-infrared and short-wave infrared increases. 2) After atmospheric correction, the three data sources The spectral curves of the same species tend to be consistent, and the Sentinel-2A water body and vegetation spectral curves can better reflect the characteristics of the ground features. 3) Compared with Landsat-8, Sentinel-2A, GF-1WFV1 atmospheric correction The NDVI of forest land increases significantly , Sentinel-2A high vegetation coverage area increased, low vegetation coverage area decreased, which can best reflect the vegetation characteristics; Sentinel-2A NDWI change is not as significant as Landsat-8 NDWI change. Chen Ling (2020) used the FLAASH module of ENVI software to perform atmospheric correction on Worldview3, and took the uninhabited area of Lop Nur, Xinjiang as an example, using the ASD measured spectral data of typical saline-alkali land and diorite in this area to evlauate the data before and after atmospheric correction of Worldview3. First, she converted the DN value of Worldview3 into radiance and apparent reflectance, and used the FLAASH module to perform atmospheric correction; then, she calculated the radiation brightness and apparent value, and resampled the measured saline-alkali land and diorite spectral data to the corresponding bands of Worldview3; finally, the results were qualitatively analyzed and compared quantitatively. The research showed that it is feasible to use the FLAASH module to perform atmospheric correction on Worldview3 data. The measured spectra of typical ground objects and reflection spectra obtained after atmospheric correction have a high degree of agreement, with the highest correlation coefficient reaching 0.80. It can be seen that there are many articles on the research on atmospheric correction. The reason is that atmospheric correction is one of the important steps in the preprocessing of hyperspectral remote sensing images, and its accuracy determines the degree of hyperspectral remote sensing application to a certain extent. The above two studies have considered the atmospheric correction process of different data sources, and proved the indispensability of atmospheric correction through experiments."
  },
  {
    "objectID": "wk3.html#reflection",
    "href": "wk3.html#reflection",
    "title": "3  Remote sensing data",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThe difference between ortho-rectification and general geometric correction confused me at first, but after consulting relevant information, I found that the main difference is whether the digital elevation model is added. Because orthorectification is a kind of geometric correction, it corrects the image of pixel displacement caused by terrain fluctuations and sensor errors, and requires elevation points or DEM. At the same time, I realized the importance of remote sensing image correction, because without the correction process, the subsequent processing and analysis would be completely futile, and it is not an exaggeration to say that it is the cornerstone of the remote sensing field. Therefore, a calibrated image is one of the most important requirements for remote sensing image processing and analysis. However, in the face of correction, there are many methods to choose. Selecting an appropriate correction model combined with image features and performing appropriate parameter adjustments also need to be considered when we deal with the problem."
  },
  {
    "objectID": "wk3.html#reference",
    "href": "wk3.html#reference",
    "title": "3  Remote sensing data",
    "section": "3.4 Reference",
    "text": "3.4 Reference\nZhuo Kong, Haitao Yang, Fengjie Zheng(2022). Research progress on atmospheric correction of hyperspectral remote sensing images. Remote sensing of natural resources,2022,34(4):1-10. DOI:10.6046/zrzyyg.2021371.\nYuanYuan Pan, Changchun Li(2018). Atmospheric correction method and correction effect of Sentinel-2A satellite. Information of Remote Sensing,2018,33(5):41-48. DOI:10.3969/j.issn.1000-3177.2018.05.007."
  },
  {
    "objectID": "wk4.html",
    "href": "wk4.html",
    "title": "4  Policy",
    "section": "",
    "text": "The urban heat island effect means that the overall or partial temperature of an urban area is higher than that of the surrounding area. The urban area with a higher temperature is surrounded or partially surrounded by suburbs with a lower temperature, just like an island protruding from the sea. Since this type of island represents a high-temperature urban area, that’s why it’s called the urban heat island effect. Wuhan, the largest city in central China, is located in the northern subtropical zone, with the Yangtze River and Han River running through it. Like other large cities in China, Wuhan has experienced rapid development and urbanization over the past few decades. The city’s temperature changes are well represented in the central region of China. The latest research shows that the intensity of Wuhan’s “urban heat island” has accelerated in recent years. According to recent data, the urban heat island effect has made the average temperature in central Wuhan 1.8-2.0°C higher than that in distant urban areas. In summer, the temperature in some parts of the central urban area is sometimes even 5.9°C higher than that in distant urban areas. In response to this situation, Wuhan has formulated a series of policies to reduce the impact of the urban heat island effect. One of them is the “Wuhan Lake Protection Regulations”, which elaborated on the protection methods of lakes and set severe punishment standards for behaviors that destroy lake ecology."
  },
  {
    "objectID": "wk4.html#application",
    "href": "wk4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nIn order to better protect the lake ecology of Wuhan and punish those with behaviors that destroy the ecology, we can use some methods to monitor which lakes are shrinking in size, and then go to the field to investigate the causes of lake destruction. There are many data source for us to choose from, including Landsat MSS, ETM+, TM, Landsat 8, GF1-WFV, GF6-WFV and other multi-source satellite image data (Jianwei Ma, 2017).\nRemote sensing data processing method: using remote sensing processing software to perform geometric correction, georeferencing and other preprocessing on Landsat series and GF series satellite data; then combining different bands of images to obtain Wuhan Normalized Difference Water Index (NDWI), which is calculated as follows:\n\n\n\nNDWI calculating formula\n\n\nThen Convert the result raster images into vector graphics, calculate the lake water area in different years, and establish a spatial database of lakes in Wuhan. The proposed results are as follows:\n\n\n\nDistribution of water area across years\n\n\n\n\n\nChange of distribution of water area in Wuhan. Red legend means diappearing area, yeallow means increased area and blue means non-changed\n\n\nwhen we get outputs like this, we can pay much attention to those lakes shrinking fast to corrospond to the action of protecting the lake of Wuhan. By doing this, city can acquire better absorting-heat ablity and Ultimately, it is benifitial to the decrease of UHI."
  },
  {
    "objectID": "wk4.html#refelection",
    "href": "wk4.html#refelection",
    "title": "4  Policy",
    "section": "4.3 Refelection",
    "text": "4.3 Refelection\nAt the policy level, although ensuring the integrity of the lake can meet the mitigation needs of urban heat island, population growth and urbanization will conflict with it. The process of urban development and expansion will definitely affect the ecology of the lake. In this process, increased competition for land from humans and waters is an urgent concern for authorities. In terms of research methods, when the research area is large, the single threshold method is often not effective in extracting small water bodies. And the post-processing workload is heavy because the pixel-based water body extraction is prone to “salt and pepper” phenomenon and the extracted patterns are too fragmented. Therefore, it may be considered to use the object-oriented segmentation of water body extraction algorithm to perform multi-scale segmentation of the image, since it fully considers the characteristics of the spectrum and shape of the ground objects, and it can divide the entire image into numerous homogeneous patches, which can effectively avoid the “salt and pepper phenomenon”. Ultimately, the extraction result is more complete, and the extraction of small water bodies is more effective."
  },
  {
    "objectID": "wk4.html#reference",
    "href": "wk4.html#reference",
    "title": "4  Policy",
    "section": "4.4 Reference",
    "text": "4.4 Reference\nJianwei Ma, Shifeng Huang, Zongnan Xu. Satellite remote sensing of lake area in Wuhan from 1973 to 2015. Journal of Hydraulic Engineering,2017,48(8):903-913. DOI:10.13243/j.cnki.slxb.20170097."
  },
  {
    "objectID": "wk5.html",
    "href": "wk5.html",
    "title": "5  An introduction to Google Earth Engine",
    "section": "",
    "text": "This week basically GEE is introduced and here are what we need to know about GEE:\n\nWhat is GEE?\n\nThe full spell of GEE is Google Earth Engine, from my perspective, it’s an online geogrophic platform which involves various satellite image datasets, enabling people to do some real-time analysis based on Javascript coding language.\n\nImportant Features of GEE\n\n\nMassive datasets-including different kinds of data sources\nIt permits geospatial analysis at scale-meanning large scale analysis can be done through it\nRespond quickly-it uses its own online server rather than local server\nCode based platform-all we need to do for the analysis is coding on the scipt box\nJavascript Coding Language\nScale (resolution) is set by the output not input\nAutomatically convert data into the Mercator projection (EPSG: 3857) when displayed\n\nNow let’s go through some codes and see what’s happening, but before that, it is worthwhile having a look at the basic work page of GEE:\n\n\nPoints in GEE\n\nWe can use the following code to pin a point in the map:\nvar point = ee.Geometry.Point([77.216721, 28.644800]);\n\nThen rename this point with “Dheli” to make it more comprehensive\nMap.centerObject(Dheli, 10);\n\nLook how it like in GEE:\n\nA lot of cool stuffs can be done in GEE, like adding shp file into assets,mosaicing and clipping, etc. But I wouldn’t cover too much about them in this learning diary. Actually what relly impresses me is NDVI can be done in GEE just by using a few rows of codes:\nvar NDVI_1 = clip.select('SR_B5').subtract(clip.select('SR_B4')).divide(clip.select('SR_B5').add(clip.select('SR_B4')));\n\nMap.addLayer(NDVI_1, { min: -1, max: 1, palette: ['blue', 'white', 'green']}, 'NDVI1');\nI can get something like this:\n\nWhich is really awesome, since index value can be seen at the top right console box when I click the map and get a point."
  },
  {
    "objectID": "wk5.html#application",
    "href": "wk5.html#application",
    "title": "5  An introduction to Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nResearch topics in GEE are various, including land use change, agriculture, ecology and disaster detecting, etc. Here I choose two typical analysis to introduce.First one is crop yield prediction. Lobell(2015) estimated the yield of corn and soybean in middle west of US on GEE platform, he used lots of remote sensing images、weather data and types of crop image data, and the estimated results is consistent with the data that reported by farms. Sencond, Johansen(2015) uses GEE platform to adopot different algorithms to analyze images from Lansat 5TM and Landsat 7TM, and extracted the vegetation data of Queensland, with which he compared the data that states government released, finding that the accuracy is lower than that released by goverment, nevertheless GEE provives an automatic and rapid dectect the destructino of vegetation. Both analysis above utilize and introduce the use of GEE, which is considered as a quick and precise way for the researchers to process data, it is true indeed, when engaging with GEE platform, a lot of complitcated procedures and requirments are no longer needed, which means that we can have more time spending on the analysis itself."
  },
  {
    "objectID": "wk5.html#reflection",
    "href": "wk5.html#reflection",
    "title": "5  An introduction to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThis section I am gonna talk about the pros and cons about GEE from my perspective.\n\nPros\n\n\nIn terms of data types, compared with other cloud platforms, GEE supports more types of geospatial data and provides free services to all users. It is currently the most popular cloud computing platform in earth system science and is widely used to deal with data in multiple fields related to environmental changes, moreover, GEE internally provides background computing and storage capabilities inherited from Google. This enables users to select the required data from millions of images according to various spatial and temporal specifications .In terms of data analysis, GEE has a more comprehensive functional scope, and it also has the ability to analyze geospatial big data.\nIn terms of algorithms, GEE can be used to analyze the advanced algorithms and interactive programming environment of geographic big data. The machine learning algorithm in GEE allows convenient data processing and information extraction, and supports various image processing algorithms. In terms of API, although GEE’s API only include JavaScript and Python, it is enough to meet the needs of most users. GEE also holds long-term sequences of Earth observation records, which play a vital role in environmental monitoring and analysis.\n\n\nCons\n\nGEE can only display global geospatial data in two dimensions, and lacks more advanced visualization capabilities, like 3D map. Also, GEE is a commercial product, and the security of personal, institutional, and national data remains an issue. Although GEE provides near real-time data, it is limited by its computing resources and supporting algorithms."
  },
  {
    "objectID": "wk5.html#reference",
    "href": "wk5.html#reference",
    "title": "5  An introduction to Google Earth Engine",
    "section": "5.4 Reference",
    "text": "5.4 Reference\nHongzhen Tian,Na Wei,Huan Li. Research progress at home and abroad based on Google Earth Engine[J]. Journal of Nanyang Normal University,2022,21(6):41-51. DOI:10.3969/j.issn.1671-6132.2022.06.008.\nJOHANSEN K, PHINN S, TAYLOR M, et al. Mapping woody vegetation clearing in Queensland, Australia from Landsatimagery using the Google Earth Engine[ J] . Remote Sensing Applications: Society and Environment,2015,1:36-49.\nLOBELL D B, THAU D, SEIFERT C. A scalable satellite-based crop yield mapper[ J] . Remote Sensing of Environment,2015,164:324-333."
  },
  {
    "objectID": "wk6.html",
    "href": "wk6.html",
    "title": "6  Classification I",
    "section": "",
    "text": "This week’s leture is mainly about some application scenarios of classification and what kind of processes are used during the analysis.Basically, things couldbe done through classifying are as following:\n\nUrban expansion\n\nLandsat satellite image data could be used to dectect and see what’s changed during a centain period of time in a city, through which we can know what city morphology will be like.\n\nAir pollution and LULC(land use land cover)\n\nIt can be illustrated through charts that how the relationship between air pollution and LULC is and measures couble be implemented based on the results.\n\nMonitoring illegal logging\n\nA good example is in Brazil, local officers use these steps to find potentiao illegal logging areas:\n\nLandsat data for monitoring forest loss and illegal logging\nPre-processing, including(i) image resampling, (ii) conversion of raw digital values (DN) to top of atmosphere (TOA) reflectance, (iii) cloud/shadow/water screening and quality assessment (QA), and (iv) image normalization\nCreating metrics\nFeature space, which means deploying scattergram of two bands\nTraining data (in supervised machine learning),methods are like Random Forest, SVM or maxmum likelihood could be used in this step\nClassification (supervised or unsupervised),then generate the result.  Source:Hansen et al. 2013\n\nHow we deal with the remote sensing data in the classification? Gnerally speaking, there are two methods, supervised classification and unsupervised classification. Supervised classification is a classification method that requires learning and training. We need to select samples ourselves and learn before classifying; unsupervised classification does not require manual collection of ground object sample point data. Most of them are automatically classified by clustering methods, and we can classify while learning.Typical methods will be introduced in the following:\n\nUnsupervised classification\n\n\nk-means analysis\ncluster bustering with isodata\n\n\nSupervised classification\n\n\nmaximum likelihood\nsupport vector machines\n\nThere are lots of information online, so I am not gonna elaborate these methods in detail. Honestly speaking, although some concepts seem to be deep and abstact, when we use them all we need to do is click some buttons and set proper appropriate parameters in those RS processing software or platform.\nHere are CART results used to classfy the Shenzhen city \nthere are difficulties in doing this for sure, and the most impressive one is when I got the image after filtering clouds, clip function couldn’t be processed, and it showed “clip function is not defined”, after going through the practical introduction and checking some simliar quetions posted on geek website, I realized that when we clip, we basically refer to one image’s clipping, rather than a set of images. Therefore, I use mean function to get the mean image of Shenzhen, then it was easy to clip using the following code:\nvar meanImage = waytwo.mean();\n\nvar waytwo_clip = meanImage.clip(shenzhen)\n\nMap.addLayer(waytwo_clip, visualization, 'waytwoRGB_clip');\n\nHere is what I got:"
  },
  {
    "objectID": "wk6.html#application",
    "href": "wk6.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nI found one article really interesting which is about forest fire historically evaluating.\nLijun Mao(2022) took the pilot area of Qianjiangyuan National Park and its surrounding 10km buffer zone as the research area, based on the GEE cloud platform, Landsat satellite images and satellite forest fire monitoring data, combined with visual interpretation and spectral index method to quickly extract the burned area, and counted The change law of fire occurrence time, frequency and burned area. He also used the landscape index to describe the spatial pattern of the burned area. The results show that: from 1999 to 2019, there were 19 forest fires in the study area, of which forest fires occurred frequently in spring and winter, respectively accounting for 47.37% and 42.11% of total; in 2013, the average coverage of a single forest fire was the widest (83.54 hm2), and in 2011 the number of forest fires occurred the most (6 times), and the area of the burned area was quite different, while in 2014 and 2019 Only one fire occurred each time; the total burned area in the study area was about 766.55 hm2, showing a trend of first increasing and then decreasing during the study period. The burned area in Qianjiangyuan National Park was only 9.05 hm2 (2011 and 2014 were respectively 9.04 hm2 and 0.01 hm2). This research method is suitable for quickly obtaining fire information at a resolution scale of 30 m with the help of free historical Landsat data, establishing spatially clear historical data files of disaster situations, and evaluating disaster management effectiveness of national parks in a timely and objective manner.\nBut I think there are two limitations.First, it lacks accurate and complete official historical fire records; moreover, due to the early age of most of the fires and the complex topography of the area, it is difficult to conduct field survey work."
  },
  {
    "objectID": "wk6.html#reflection",
    "href": "wk6.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis week’s talk is mainly about GEE-based remote sensing image classification. For the GEE part, one difficulty is code understanding and debug, which are full of consistent trials. However, GEE really shows its power to me as an online platform. A wide range of topics and fields can be analyzed through it, more importantly, the data is all free and I don’t need to down it to the local repository, it is so effective to load data from cloud server and I could really use the saved time to figure out the codes."
  },
  {
    "objectID": "wk6.html#reference",
    "href": "wk6.html#reference",
    "title": "6  Classification I",
    "section": "6.4 Reference",
    "text": "6.4 Reference\nLijun Mao,Xujian Mao,Xiaoming Xue. Research on Dynamic Changes of Forest Fires in Qianjiangyuan National Parks Based from GEE Platform[J]. Journal of Southwest Forestry University, 2022,42(9):158-164. DOI:10.11929/j.swfu.202108036."
  },
  {
    "objectID": "wk7.html",
    "href": "wk7.html",
    "title": "7  Classification II",
    "section": "",
    "text": "This week’s leture goes deeper in land cover classification and accuracy testing. For the former, object based image analysis is introduced, which involves considering shapes based on the similarity (homogeneity) or difference (heterogeneity) of the cells. Simple Linear Iterative Clustering(SLIC) Algorithm for Superpixel generation is the most common method, it will\n\nuse regular points on the image\nwork out spatial distance (from point to centre of pixel)\ncolour difference (RGB vs RGB to centre point)\n\nBut for sub pixels, how to analyze them is another way playing around, and basically it means a pixel is composed of a range of land cover types.SMA(spectral mixure analysis) is another name of sub pixel, which determines the proportion or abundance of landcover per pixel.\nThen the second part covered is accuracy, and there are three parameters are considered in RS:\n\nPA Producer accuracy (recall or true positive rate or sensitivity)\nUA User’s accuracy (consumer’s accuracy or precision or positive predictive value\nOA the (overall) accuracy\n\nTo test the accuracy of the existing model, we also need to split the data into training dataset and test dataset, then cross validation can be used to calculate the accuracy of the model. Also, to avoid the impact of spatial autocorrelation, what we can do to help is as following:\n\nObject based image analysis\nSpatial cross validation\n\nWe can apply these concept into practice on GEE platform:\nSpatial autocorrelation can be done in K-means in Daressalaam:\n\nwe can see it basically generates big blocks, in regard of this, SLIC method mentioned above could be used, and result is like this:\n\nCombining the ndvi and standard deviation, we could classify the image and here is what I get:\n\nIt can be seen the classifcation result is not that good, since there is not adequate samples for each type of land use. Anyway it’s better than nothing！"
  },
  {
    "objectID": "wk7.html#application",
    "href": "wk7.html#application",
    "title": "7  Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application\nHere I find a research closely related to this week’s content.Aiming at the high degree of fragmentation of garlic planting in Kaifeng City and the difficulty of high-precision and rapid extraction of optical data, Zhanlin Ma(2022) chose to integrate the backscatter coefficient of Sentinel-1 satellite and Sentinel-2 satellite based on GEE, Random Forest, and object-oriented methods. The spectral, spectral index and texture features were applied to 10 m and 20 m spatial resolution sense data added to the vegetation red edge band,respectively, to explore the performance of different feature combinations to improve the recognition accuracy of garlic. The results showd that: when the segmentation scale of Simple Non-iterative Clustering (SNIC) is 5, Gray-level Co-occurrence Matrix(GLCM) The neighborhood value is 4, and the first and second principal components are selected for the 7 texture features, the overall classification accuracy and Kappa coefficient are the highest with the use of Sentinel active and passive remote sensing data with a spatial resolution of 10 m. The study provides technical reference for remote sensing data to identify large and small economic crops with the same or overlapping growth cycles.\nThe simple non-iterative clustering (SNIC) algorithm is improved based on the SLIC algorithm, which effectively improves the clustering efficiency, the study above used this method to classify and detect the distribution of garlic, whose featrue parameters are also considered into the algorithm. It tells us when using classifying method, there is a need to choose the proper and appropriate parameters in the model in different scenarios."
  },
  {
    "objectID": "wk7.html#reflection",
    "href": "wk7.html#reflection",
    "title": "7  Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nCompared with traditional image downloading, atmospheric correction, geometric correction, splicing, cropping and other manual processing processes that take several days, GEE significantly improves the efficiency of data calculation and analysis. I feel like this especially when I finish the practical part, which would usually take days to complete if we do it in other software and could clash any time when engaged with so much data. GEE-based analysis like classification that will involve huge calculation flow and big volume of data will become more and more popular for sure."
  },
  {
    "objectID": "wk7.html#reference",
    "href": "wk7.html#reference",
    "title": "7  Classification II",
    "section": "7.4 Reference",
    "text": "7.4 Reference\nZhanlin Ma, Huazhu Xue, Changhua liu(2022). Identification of garlic based on active and passive remote sensing data and object-oriented technology[J]. Agriculture engineering,2022,38(2):210-222. DOI:10.11975/j.issn.1002-6819.2022.02.024."
  },
  {
    "objectID": "wk8.html",
    "href": "wk8.html",
    "title": "8  Temperatrue",
    "section": "",
    "text": "This week mainly focus on temperature and policy, and urban heat island(UHI) issue is posed at the very beginning, whose definition is certain spots in a city are much more hotter with higher temperature than the surrounding environment due to a series of complex human activites, like carbon dioxide emission, polution, factory operation, etc. Two main direct causes of UHI coule be:\n\nMore dark surfaces that retain heat\nLess vegetation that cools the environment\n\nUHI hurt human being in three aspects:\n\nSocial damage\nEnvironmental damage\nEconomic damage\n\nFortunately, global policies targeting at addressing the UHI issue has been proposed, it is covered from “New Urban Agenda” to “SDGs”. However, local policies also are needed to be made to response this issue from realistic and practical level, here are some examples:\n\nBarcelona Superblocks\nMedellín Green Corridors\nSydney’s western suburbs\n\nWe already know it’s an serious issue we can’t neglect, then what exactly do we set up every step? More specifically, what can city do based on the data they have? Take Fremantle for example, they use Landsat temperature image data(they believe) from one day in a month, with a 30m resolution, here is what this city would like to achieve:\n\nMaintain and enhance vegetation\nIncrease quantity and distribution of green areas/tress (20% canopy coverage)\nEncourage greening of hard surfaces (e.g. parking) and in private realm\nFirst city to use data to inform their cooling / greening strategy\n\nWith all the data and policies, it seems that this issue could be adressed easily, however, during the procesure, there are usually full of misconducts, which are mainly related to inequality, like do we take measures equally and equitably?\nFor the practical, we can apply Landsat data to plot a mean summer temperature image, take Beijing for example:\n\nThis can also be done using Modis satellite products:\n\nWe can see the difference bewteen these two plots is the latter is more vague not as clear as the first plot, this is because the resolution modis have is 30m scale while the Landsat has 10m scales. But Modis have more images in a certain period of time, which provide us with the chance to do a time-series analysis.\n\nThis enables us to do more mathmatical calculations since we have this two dimension expression of data."
  },
  {
    "objectID": "wk8.html#application",
    "href": "wk8.html#application",
    "title": "8  Temperatrue",
    "section": "8.2 Application",
    "text": "8.2 Application\nTaking the main urban area of Guilin city as the research area, Peiqing Jiang(2020) used the random forest algorithm to classify the Landsat remote sensing images in 2010, 2014 and 2018 based on GEE, and used the single-window algorithm to invert the surface temperature. The results showed that: 2010—2018 The average temperature in the main urban area of Guilin City showed an upward trend in 2010, with a total increase of 1.29 ℃ in 8 years, and the temperature zones of each level changed from lower temperature zone, low temperature zone and medium temperature zone to high temperature zone and higher temperature zone; lower temperature zone and low temperature zone is mainly distributed in areas covered by vegetation and water bodies, while the medium temperature area, high-temperature area, and higher temperature area are mainly distributed in construction land and unused land-covered areas. The following figure is the LST results from three different year:\n\nSource:Wanfang\nActually I have one doubt about this article which is the colleting time of the image data, if collected in different time, data analysis is not convincing to readers and the public. If it needs to calculate the mean temperatrue of the whole year, it has to be mentioned, which I don’t see in this article. Maybe it can be more clear about when the data is collected and specify the time they use for analyzing."
  },
  {
    "objectID": "wk8.html#reflection",
    "href": "wk8.html#reflection",
    "title": "8  Temperatrue",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nUsing GEE, we can quickly find the temperature product from different satellite sources, like Landsat or Modis. Despite they may have different resolution, it still gives us the oppotunity to analyze issues under the various situations the city are facing. Sadly, there is no satallite that can produces consistent temperature products with precise resolution so far, the best satellite now is Sentinel-5P, which still can’t meet the needs of deeper temporal analysis. However, what’s good is algorithms can be easily conduct through a rows of codes and it won’t cost us too much time, which is really fascinating."
  },
  {
    "objectID": "wk8.html#reference",
    "href": "wk8.html#reference",
    "title": "8  Temperatrue",
    "section": "8.4 Reference",
    "text": "8.4 Reference\nPeiqing Lou, Bolin Fu, Hongchang He et al(2020). Quantitative remote sensing analysis of thermal environment changes in the main urban area of Guilin based on GEE[J]. Journal of Guilin University of Technology,2020,40(2):330-337. DOI:10.3969/j.issn.1674-9057.2020.02.010."
  }
]